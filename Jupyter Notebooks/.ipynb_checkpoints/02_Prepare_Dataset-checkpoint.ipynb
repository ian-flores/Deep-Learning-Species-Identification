{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Ian Flores & Alejandro Vega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from six.moves import cPickle as pickle\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display as disp\n",
    "from IPython.display import Image as Im \n",
    "from scipy import ndimage\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## image size \n",
    "image_size, size = 28, 28\n",
    "\n",
    "## Shifts \n",
    "num_shifts = 1\n",
    "\n",
    "## Number of imgs per class\n",
    "min_imgs_per_class = 1\n",
    "\n",
    "## Number of imgs per class after augmentation\n",
    "min_augmentation = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping Spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the architectures we are using in our models, we want all spectrograms to have the same size, because the models don't allow for dynamic size input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squareAndGrayImage(image, size, path, species, name):\n",
    "    # open our image and convert to grayscale \n",
    "    # (needed since color channels add a third dimmension)\n",
    "    im = Image.open(image).convert('L')\n",
    "    # dimmensions of square image\n",
    "    size = (size,size)\n",
    "    # resize our image and adjust if image is not square. save our image\n",
    "    squared_image = ImageOps.fit(im, size, Image.ANTIALIAS)\n",
    "    squared_image.save(path + '/' + species + '/squared_' + name)\n",
    "    squared_image.close()\n",
    "    #print(ndimage.imread(path + '/' + species + '/squared_' + name).shape)\n",
    "    \n",
    "def squareAndGrayProcess(size, dataset_path, new_dataset_path):\n",
    "    # if our dataset doesn't exist create it, otherwise overwrite\n",
    "    if not os.path.exists(new_dataset_path):\n",
    "        os.makedirs(new_dataset_path)\n",
    "    else:\n",
    "        shutil.rmtree(new_dataset_path)\n",
    "        os.makedirs(new_dataset_path)\n",
    "    \n",
    "    # get a list of species folders in our dataset\n",
    "    species_dataset = os.listdir(dataset_path)\n",
    "    \n",
    "    for species in species_dataset:\n",
    "        os.makedirs(new_dataset_path + '/' + species)\n",
    "        species_images = os.listdir(dataset_path + '/' + species)\n",
    "        for image in species_images:\n",
    "            image_path = dataset_path + '/' + species + '/' + image\n",
    "            squareAndGrayImage(image_path, size, new_dataset_path, species, image)\n",
    "\n",
    "dataset_path = '../dataset/spectrogram_roi_dataset'\n",
    "new_dataset_path = '../dataset/squared_spectrogram_roi_dataset'\n",
    "squareAndGrayProcess(size, dataset_path, new_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"../dataset/augmented_spectrograms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift \n",
    "## Have to find a way to create and copy the old directory #########\n",
    "\n",
    "#To shift UP up to num_shifts pixels\n",
    "for folder in os.listdir(new_dataset_path):\n",
    "    species_pictures = os.listdir(new_dataset_path + '/' + folder)\n",
    "    os.makedirs('../dataset/augmented_spectrograms' + '/' + folder)\n",
    "    for image in species_pictures:\n",
    "        the_image = np.asarray(Image.open(new_dataset_path + '/' + folder + '/' + image))\n",
    "        for i in range(num_shifts+1):\n",
    "            pre_image = the_image.reshape((size,size))\n",
    "            shifted_image = shift(pre_image, [(i*(-1)), 0])\n",
    "            shifted_image = Image.fromarray(shifted_image)\n",
    "            shifted_image.save('../dataset/augmented_spectrograms/' + folder + '/' + 'shifted_up' + str(i) + '_' + image)\n",
    "            shifted_image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To shift down up to num_shifts pixels\n",
    "for folder in os.listdir(new_dataset_path):\n",
    "    species_pictures = os.listdir(new_dataset_path + '/' + folder)\n",
    "    for image in species_pictures:\n",
    "        the_image = np.asarray(Image.open(new_dataset_path + '/' + folder + '/' + image))\n",
    "        for i in range(num_shifts+1):\n",
    "            pre_image = the_image.reshape((size,size))\n",
    "            shifted_image = shift(pre_image, [i, 0])\n",
    "            shifted_image = Image.fromarray(shifted_image)\n",
    "            shifted_image.save('../dataset/augmented_spectrograms/' + folder + '/' + 'shifted_down' + str(i) + '-' + image)\n",
    "            shifted_image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To shift to the left up to num_shifts pixels\n",
    "for folder in os.listdir(new_dataset_path):\n",
    "    species_pictures = os.listdir(new_dataset_path + '/' + folder)\n",
    "    for image in species_pictures:\n",
    "        the_image = np.asarray(Image.open(new_dataset_path + '/' + folder + '/' + image))\n",
    "        for i in range(num_shifts+1):\n",
    "            pre_image = the_image.reshape((size,size))\n",
    "            shifted_image = shift(pre_image, [0, (i*(-1))])\n",
    "            shifted_image = Image.fromarray(shifted_image)\n",
    "            shifted_image.save('../dataset/augmented_spectrograms/' + folder + '/' + 'shifted_left' + str(i) + '-' + image)\n",
    "            shifted_image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To shift to the right up to num_shifts pixels\n",
    "for folder in os.listdir(new_dataset_path):\n",
    "    species_pictures = os.listdir(new_dataset_path + '/' + folder)\n",
    "    for image in species_pictures:\n",
    "        the_image = np.asarray(Image.open(new_dataset_path + '/' + folder + '/' + image))\n",
    "        for i in range(num_shifts+1):\n",
    "            pre_image = the_image.reshape((size,size))\n",
    "            shifted_image = shift(pre_image, [0, i])\n",
    "            shifted_image = Image.fromarray(shifted_image)\n",
    "            shifted_image.save('../dataset/augmented_spectrograms/' + folder + '/' + 'shifted_right' + str(i) + '-' + image)\n",
    "            shifted_image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset_path = '../dataset/augmented_spectrograms/'\n",
    "#new_dataset_path = '../dataset/squared_spectrogram_roi_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Myrmeciza hemimelaena sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB9UlEQVR4nC3POZbcRhAE0IjIrAJ64TJ8tPR4AJ1YR9MVaIjL9Ew3GqglU4Zkf+sTf73UH9/bn0fl3/Vy7eXYztuzPCzH1VElj/PFLc52+fzEVK3LtMRujg9LWefL1z32l/Hlj9sz7udP7dU3/abjjX5rvCN6P6+PzPatfrgt10+2umMLe0RuHsd0axHtmlV+LujV8d1D/mNf9/a8vpY7f30rx2Nn/ZlyMNHwnPucec/R2nyr95tGu0d11OGbP1RKrrfxqt8f/1m34+WIV14c+9LF07RR2KPg6xFvu41fcT//FCZCNDKRcxKF/Wgx3m/7eDjmDqu9lKUdel4es25W8/nu6RA4kImOBMBIkgBYaG0KnIjggWBSMyQC5Gq2h1DQovgy1mCdveVb22cUc5yKYErCbCJkSmAgkUhOQeDJa5Pae7rOqsFSXc87njGESSkmiOyNZC5QJktaD6HTLAbI6IekXGCZLOEtHEU1o3GBuz1AtUBkBJY6BCYzJkyQBYFkJgjAU5htRI8gBlcaxEK6oK4QWJKSWBSNsPSaTEPXCIEFEElT/o8ghM4RQoxF5VKyEVscIc2l+iZr/llIWMoc/1VDmiQHKUgY04K+YMhPuU35HhNdfuEQPq678UhD5IVnTtgULTk0hGttYktD5IkLA5qEEsH+L2faRU18D+d4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Microcerculus marginatus sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAANElEQVR4nGNgwAMYZ3yxuM120Zrz2v8vvnt+fOP2PvnsjbPYVpFnnr+OMOHTOSo5KjnsJAHMrBCwXeZYTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Eleutherodactylus coqui sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACc0lEQVR4nH3ByXLkNBgAYFn6tXm3e0nc6VT1kAM3rhx5Mp6PM1VwmKKKyTLJJL053mRLlizegO9D6H8Ev8Nd+7rv8ebo3fO6mLWQH9XqadHVuAcYZxVqHb5HE930gYz8lGibACRxDgSpmQUMAhQuGx3MInzddG+bVShyhUFYsCLCP02pC7Y7YlLr3KvPItk+4sKXrIP6SiWxNX+4lXZt0L0D//7HE8Q/zEpeLXXiQnfJOPPG04qmjW4Rhzb207pHSyemJfZfKW8nvgr82zlzgNs76Zjx8TzQJB47fKScLrY2lrgF4y2lXYc24pNW2VyFp9tqp+pWHiJCMI1zj/dbCw93gZ0o/SX+R5RN+txzBhDAEHKiLYNx+uvl5zl7OXTSP0cWqQS0Tbi3dahe9sMY+SEjgTWEl2TxPcZGdG/IL7pFQXobAl21M4abNDLU4NI1f/+ZHCL+K8ulj28K5qaIctqPuMCJi7/8dkdUh8/h7q2l5hjcY7vIywIx8K4xIVsoaOC8XNBzT4hLQrpd7AAjIIltwITKXJTRGZVLBykWoUpqfJLRljaC2zEzSIbD/aFoBz6TycQIq7l18kg3jxOT6iarZzPnmvIzJSqCH/ElRt95LT6uD77Uazboz3x5cvGRM8iXRE3865RmtIuaJnt0+ylRi5u4lLgi3J2Yxqi81bhp2lbZnLYRHbgUuECtOKovB+IUMo5d18m/VHV46s2ocOFA5MXMqPLVLMLS0EsdBNPZgP4GsmJmmFKUva5OyjYi4WCxOpHsytdQG/hOoDNkHkk+X0dK9v7EOQ50WuBvH/2FhZ/nbqmJKEPnXYbf+Q7XItP/AWl+WGbC9c+bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Epinephelus guttatus sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB60lEQVR4nH2SS28TAQyEx4/d7G7bNKGPqCoCDhRxQULc+af8g/4VbpwrKCrqI/QVmm6TXXs4pBUX4DuMLM3B9thyWF8e32E4nMVkenc1G1bTo4Nni+nyxfLXoeI//MXkH5MEIIA8ofZUwT9P6hvZWy+bwXjcze9kLd5tlD82R9Z8h98vBuHuqmVRKjMrZF0UZZN1ATdVASlJkhlI9qHMYCY8Mwhm4Km5qqqoEgq/advYPJvNDnYiIOteVmMhHhqP1/DsWmX/MO/6CDFRUUMU4QVLOEQFqqqqFFntKSQphCtEmJCMCJolCWZmZhD+5miEn9e7k/PTKo+23/ajZuP8qpPGrzfhJQyZYvcd8lfTdV0XyzbUc9FBk5kEKSKiKiqqqiKionBzh6tB1WCGRPYJEQYS/v5517d1ft3x8cXLjbOzZrooy209uW1O4GVtHZqlFUXpRcVgv3S4ZI8ezsyMyNX0QQAgUyAQOAhVNTdbiRS9m4kqBd5dbfmgGTTohqPKinry4UEut8zmX0Zwhoiol5laFOquFehuXlCgtsqTFCHJRAaTZJLQlkySyL5PUiyhMBBWOvzTx+u2WK7F8cWEe/Vg99t+dbuXF4P9V6fwObO3JPquJykWFBhTvHS4AQIA8nhMefxcJqHEv/kNi9Id3L40aqkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Megascops nudipes sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAMklEQVR4nGMsl/4s8ZVR8Mdv8e/fWb795P/JzvjhL+d3pt8MzBxMDHjAqOSo5LCTxAsAuC0NyjvxJyUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Basileuterus chrysogaster sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACDUlEQVR4nH3BWY7TQBAA0Fq62u0lCcsHiBtzTSQkQMxkMo7da1VxA94D+A/8vpYDg32tu0b9dn9Dn768NDo+XX5X2ruynqW2OnqvNLgaiqv6OjGpr2w6BAiFIsugkgL3wTNrGE7YXWM016KJD2Wfs1HdjYOHbqnpkfsYZTQV5/w2kLjzTG4IAN3Zj8oYI7Je5ijQrtGJ+xYzAV0XoQ63D3NA2BZx1yDB2vzx2YFWzHu0cFELxyz8NFt6KNr7NTO05lSH+iHd7ajX2nKlC0Bz4upOspz1AOthEYhhkJAPraMNmAICZFbyMPD0YWEC0k4Lz9ckcWXgLUabrIdSjWQlRE1GUREpItrkYRSJ8QaQiDahCKHcScbFCyWi8p5odtUbkLVnXNvwHG9xsp0/hDSV68XDy4GEVGZRqGOTpwdYJQQbi0iwFqmOrCBkLVpiQSxuZ/cKjVMnRC2EObzs3MH2jhA410DcD6M00wkQTfPZpD1cpijH/ZFhL0yTZJsoRgLbFvQ48cb+/hysYyJmkKuES8Fb19t4llxa3tLAaSA96sWZnloooeL5DuWwui6uBEJU5X6iVnVF8ZBSnNOUfJPeK5HU9uOXZcikwqz+ae5nJRDRR+jM8By2yM+/x9b0z1IrtfoZX8jmAPuYIbTK51iK9tdXHx/H33Yv2DwQFlgqjyGhThBpv5WKP197uj32f7eIbp2pZEoTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Eleutherodactylus cochranae sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9klEQVR4nMWRO08DQQyEZ7zeC4+AQECDRMP/L/glVECVFiFRhIcC5Ha9NsWdToQiDYoYydVo/Hlk4iaRnElIEtA7XSO/+O2iezoPwRb9h6ngIAwDAAEAIKE4CxIz8eho4sklekeq6XQuCmKKcTPJ3V27wZxuJgCFOSVEPIRVXFqJWhg0AIrFKg77juH76bPr22vLS+/a/P46QWE1rJLhOSprKy2Kk2NypE3IsS7/WmVzLTgYAUJRDbVSWtNcYM1NIiKQ2Fxxtz54R87Lt5Orh6OLXj6OV6l85cu9x2dFtVYBlr5YKWZqHhGOxFb1d48fzF29bKv5DRHudwKz9pc6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Eleutherodactylus juanariveroi sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABpElEQVR4nH3Qu5ITQRBE0cys6h5J+4jgB/l/g8DZh0YzXZVYEAsG17r24ff1HLLzbPL17nc87bW/Ok55E77kL08AGht01rbami913uY+8rIS7xyhkFFOG1R2pyooCwdkFSc3PojAuN26mGdMHf6WflE7mFgAFdfZppaSq2+BTdukjdHQirNzQcOKmJCGtknTsZCVC3E4wlJMBTe5Gx7a0AhBQbKRVS5aqOW+zCc2NmFKk8Vrr1pidqDsNkGWF7kTsDEM6thmtwsBxWd/Rv5oQsuvV4/8DUcaguD440jZTdX6uOYjr/Hkz9eMOCKGefkL/t+yoehzNrNvOvdUKKqBt3ne1ADRMOlIFykQMJaYui47tsqdeX56s8F64xU4alfaiCgustthAN454OpSLtbZQ4Gs9+p2d18eFjVbY2E1h4jsvV3udh4QGNZKa52FoM7DSjSKabtpHaNxfzRHxOO+Yri8MhtdyWQBU6glF2OZtrthunbxvOtZ2PfTd2z3Rfeq4nLVT1ldJkK20QQAoQ3DUI23jwxex1n3ehBNXPperN73/8L/Av3ZLgIgeE6yAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Basileuterus bivittatus sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB/klEQVR4nH3BS3IbVwwFUOAC79NkU6QySHnmyvK87gySuEqSRZHd/T4AsgOfwz+SkZIhjsLy+t9fX8f3vwWSfpYYmgQ9SBtBOCdJWU5yzvbSMz0UTGIgHeIhoJM71T+3XdacJ4Z5SCYmIdK8En97eb1xxXm9kLJBfHIkcdR0JrlgVUU2LxVKIPcIUBjTMWl87Vs4PgIKJwsOMqLJOxPHmPeNp5DOoR4BYiavvNDQeB7RMdk8nJQdzD6Fb+11Mw6RQax+ykkqgliIPLBIzbnWTHt44nyTxgghAbOxy5iQGWMUHmPgGA0M7xFM3NCn2U6pXHRGezYCfMacBE1MFMkcGXOKjKHqMFIhBtfsYAgLba4OyhmGpHnN6VIT2JedVxsPVNNasxW8EG5nvV6Zkmpz9bk4vepJpJx13aEaJ+yQsgNc6MXK+VfkuJqWKjn3ZSxlimhdY5k6IxlTTXoqfPUtAM05tUtt67OIKzmNjMHQKBLJVCX6bG2QYHYnE33r5f7OeshOG33Wt/f5Fop/r5d/GBrd742fY9vV5Tk3uT8X4CP9sX8VNZQCAhrl2SL2ZA2PsT2MywKlmr2cPWXfAToi57If7Xl/5AoymxPDyI9jUm/SeBzHo/98b027jc/B772DD8wN3HG0OLcHv+3ozgemtWgsFso2R+dw3mz/pN/5HxJqQQ3ImJzxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Chlorothraupis carmioli sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB90lEQVR4nAXB2W4cRwwF0MtLVlW3xtZmWC/JV+Z7Yxjwi4MkUGyNNd21kMw5gj/EsY1R+0YvKwnJzFWFwwwiGiIFmpAAg1m0M+RRfhmYtlIMmQnZ10S0+zc/4rEOgw1Rh9goibvP37VHeykH+0WbwZtEBj6X06Gf5rli2396pk8S/nApVeT5qapjvxSTpojMATXEpxFY+sFvcfOEKyQjMvqFRGxtTy3NWlUZhPZbtFhSdRHF/TyCPmaWypiwGQmInNNQ5joH0M8eRXOs0FjOgI8gIIktcbi7rNuRWHYcW/SjNsKRnEtsKacI8qbc6yrYkYQyKUJNYdCBNJBLi6kYGgE1CQ1RnZAWMdJxR5LQgQH3G2c+30saW76H8eVpORHDxXfRwnO7bBX58FgD/rQ7DelT/KEQHLyMKvL48ZjI+xYktKyI+5c4oTfNqNw/xmIzFTf8nrWFPf96K2a1q0pft5mxoqfht7+3tfTSCUVfY+Zbf50Zf/E6DQ//bl2AwJT1Oq49/rtGw/rauhuy9xnn/OdnxPsX91lLWUJnlmH49roOXP/8MTxyJcQASdd0quHbD1n2fhUBzDVRyIS3dKuGMQskd5fFbaKJUkAnllVi0BAyQioXTUHnHTJTFgkHGYAgckET4SJE5lpORIRBVHGmJxY8MCmJHvN/WSdhRw5GRxMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Hypocnemis subflava sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABy0lEQVR4nE2SS44bRxBEX2RVdXMoamAb/gD2wrr/EXQWLQx5K2EwpHua7K7K8IIcQLnI5UP8xOcv/9bxtk85f3i9Hlb99W0+q8XzcVkqEvfz/adtEIag9zQmNImAdjy0WtU1RVQuy41ITf23JeahXz7N1z3Gy+9/XEdQQwJp9LQhxxi+46l8v3ZNmf3jz2VlUT2eyiWL2tRula+3vZex73//Oa26xPxT/++8lHJ4elqDGnfBPdMGM2yDnQ76Hm2Lqo+20hlvLd2IjKc5GCPapsoJk85YW9KIjMMUAA5MhiQgbAzIGVj1uoXE1+/ruWQ578/Qu151qiB6CumyjU3WnjPYbNEqgAA6WMY5sI2NKzmkQtM/39gc5fIyPy9ep8W/lvqoRNxt4hy2rUyoJLI1ojvuGnPDKEZSeYtpi3LJsR+TWreb1+w5T+dTC2Q9en7wFQBSUaUfbmpW2Fky1OmpsK/70oLelnJwKenRStHmbaWOcbm9vAZ+n48f47mniEqpfMh5OJxuc8pDlvdWx2ndCZ48hYVpUxSnh9kpeSj7FuS7VvsRpQUYKZjdW92LqncbXaMcW9rXnj2oZCiF7owu1TD0dMaPAbxj35v6H2AkNwyrW2USAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Megascops guatemalae sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAtElEQVR4nNWSMW7DUAxDKYr299D755BdWySx/MUMdYYsWdu+gRBASCABAW+IC8exjBqjp7ViT96gNsfs4rvNf2bGC6+mvuPK7ajbhwvcVGat3Y1pQzsozYrhPSJ5EA3btgEFnhd/5Ld7CgAMwHb4BIZtQwSZ0SHPoDTFTESnbOsruBzoMIq+jl2oO9xcbOszMdoLhLnec5sqrmFY9iISBIiEmRLSyGggbQpnojOU7XiOf+9NHgvVbwbPtbbGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Eleutherodactylus cooki sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABXUlEQVR4nKWS224TQQyG/9/jyW5DsqVV1YhGPAASEs/IY3JXCQpFhdDQNtmdg83FJhxuFgnmwmNpxt98tgaYWHw7DLF08zusb84W1xHr7l2x5xe3w/WrK5mq/PshyXH7+diYKQiUFA2wXJxu7kCtTjNTZvfzF20y69bhc9aubZ5werrZdV2noWd4+SY8pLx6vX3/abnyZ9/l6vxjv7q8PGDVDJarE4Zf2EmhyVYUDjhAEBACY81I0lnnPIuy9/1iuH1ks6tRh/Qlp5l8U5m5N8IiheUpQUsWWqlWhL3A3Q9YCuHkKESAo5D/Fv8QgjsVABjo43Un3UEqJCBvFWB6yKEi94T2URW5qjdts7npwHi35ZzcfF3Z4sPFcon7jQBwHC2OLR6y//gJJEHKke3AOEN3uu5N9LHe20mf0ASbC1OtKch8NkQdbOY79h5rYhu8FSazQeQkDnES+++2PwCbUq4qsDyBpAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Eleutherodactylus brittoni sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB4ElEQVR4nHWSQVMTURCEu+e93SWbRCJgQVmllpYnD979C/7/uyiaQgqUbMDs292Z9hAsuNinuXzfYbr5ednkT0fnF9f3drny2ezDxy+3X4chqi4dGQAQjyEAPdwmQk6SQEDAJDJTgqTclGZ+NJW+yFaswZOqlKuDSmrqmTU950djv+vFFWvhJJX+qlRV1O3MRLib/dNqglmiBEWYgGTuIASAOcndCAiWbec4m99cp7bZjXU8f/uiW1+8qouKHb4xAYkej2S4JwICcwZjogFSCMIUySjACHlmWZ6VUekgW3bpuN66KG4nNIeZZXlaxqisajRAx1XnQbFLqg8N9MketBImpf3ngHCj5eQOAJBkWQ5KAJCSta/fH69/1DG499vh9N3dJZ91v8Yq6/SlMWV7JFOOpyTkSAbui/FIiYQQQigbF+yGqhSgGFaz9WYa2NpySC0yMeemoO9lQ6XDg27DHi3bu9QqA2Iy0kQCrmQgxBAEk+DuQgQEUNPDRBQIGwq/33z7zc226XKpbs+9jKMm7NbpKktwD0H7XcUT0rORyQQTIAppXxeAYM530Q+7BW7nlhZjpbvtnwNrSNfzsbPtZrfdLXHbLmwxVtp298kamMdq+GlmNAZMgaBg9kRr+H/0F7bnMEngXyg/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Formicarius analis sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA50lEQVR4nLWSu04DUQxEZxxnlyVBQiAoqPg2PpjfoIEmhCSbtT0USx4SURqIS4+Oj++DLz59fBpuJzDcfS5nrw8fhUQoSzScqQuFfqopSJLg4K5DACBJOCSW4NbWVI5SzBpaM2/uh9Vzv7LGNtsjEjuSnhNz8zy5kH7qj0chyNHGX6ESYcoYIkPSYTNvo118aTqPbfe2iXadSatefq2r5UiKmXtyHEmQeydPOP/lVQ4zRwHhlDBeWIZUksTIjJCVd4u0bFZZeucNB1tiO+l7aWZd78SehFAUipGqsKxj57GdJC/1+86G35vFkVvsjXlhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Liosceles thoracicus sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAgElEQVR4nGNkKP5mzXf8g6L47a+i8neeKCueYXS+8tju42krxgtMDHjAqCQxkoyMUA4jmiQLw3+Gv3/+M/z/95/h/9//DP//MTD8+8/wn4HhPwMDC8M3lmdsX1m/MP3885blG/vX13+YXv38+fY/09e/f5hw6/yP385BGUJDRxIAZrVA0U63NgcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Function for displaying a random photo from each class in a dataset\n",
    "def displaySamples(dataset_folders):\n",
    "    # go through each class in the dataset\n",
    "    dataset = os.listdir(dataset_folders)\n",
    "    for folder in dataset:\n",
    "        imgs_path = dataset_folders + '/' + folder\n",
    "        imgs = os.listdir(imgs_path) # list all images in a class\n",
    "        sample = dataset_folders + '/' + folder + '/' + imgs[np.random.randint(len(imgs))] # path for a random image from a dataset class\n",
    "        name = sample.split('/')[-2]\n",
    "        print(name, 'sample :')\n",
    "        disp(Im(sample)) # display our sample\n",
    "        print(\"========================================\")\n",
    "\n",
    "#print(\"Here's a random sample from each class in the training dataset:\")\n",
    "displaySamples(new_dataset_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetFolders(dataset_path):\n",
    "    folders = os.listdir(dataset_path)\n",
    "    dataset_folders = []\n",
    "    for folder in folders:\n",
    "        dataset_folders.append(dataset_path + '/' + folder)\n",
    "    return dataset_folders\n",
    "\n",
    "dataset_folders = getDatasetFolders(new_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pixel_depth = 255.0 # Number of levels per pixel.\n",
    "\n",
    "def load_image(folder, min_num_images):\n",
    "    \"\"\"Load the data for a single letter label.\"\"\"\n",
    "    image_files = os.listdir(folder)\n",
    "    dataset = np.ndarray(shape=(len(image_files), image_size, image_size), dtype=np.float32)\n",
    "    num_images = 0\n",
    "\n",
    "    for image in image_files:\n",
    "        image_file = os.path.join(folder, image)\n",
    "        try:\n",
    "            image_data = (ndimage.imread(image_file).astype(float) - pixel_depth / 2) / pixel_depth\n",
    "            #print(image_data.shape)\n",
    "            # our images are RGBA so we would expect shape MxNx4\n",
    "            # see: https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.imread.html\n",
    "            if (image_data.shape != (image_size, image_size)):\n",
    "                raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "            dataset[num_images, :, :] = image_data\n",
    "            num_images = num_images + 1\n",
    "        except IOError as e:\n",
    "            print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "\n",
    "    dataset = dataset[0:num_images, :, :]\n",
    "    #if num_images < min_num_images:\n",
    "     #   raise Exception('Many fewer images than expected: %d < %d' % (num_images, min_num_images))\n",
    "\n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('Mean:', np.mean(dataset))\n",
    "    print('Standard deviation:', np.std(dataset))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to pickle the data by species, allowing for control of the minimum images per class. Beware that this will drastically influence the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling ../dataset/pickle_data/Myrmeciza hemimelaena.pickle.\n",
      "Full dataset tensor: (352, 28, 28)\n",
      "Mean: -0.03327564\n",
      "Standard deviation: 0.10731486\n",
      "Pickling ../dataset/pickle_data/Microcerculus marginatus.pickle.\n",
      "Full dataset tensor: (96, 28, 28)\n",
      "Mean: 0.07054525\n",
      "Standard deviation: 0.12668712\n",
      "Pickling ../dataset/pickle_data/Eleutherodactylus coqui.pickle.\n",
      "Full dataset tensor: (104, 28, 28)\n",
      "Mean: -0.03885141\n",
      "Standard deviation: 0.10395328\n",
      "Pickling ../dataset/pickle_data/Epinephelus guttatus.pickle.\n",
      "Full dataset tensor: (136, 28, 28)\n",
      "Mean: 0.022303699\n",
      "Standard deviation: 0.13731049\n",
      "Pickling ../dataset/pickle_data/Megascops nudipes.pickle.\n",
      "Full dataset tensor: (120, 28, 28)\n",
      "Mean: 0.09298875\n",
      "Standard deviation: 0.14650404\n",
      "Pickling ../dataset/pickle_data/Basileuterus chrysogaster.pickle.\n",
      "Full dataset tensor: (40, 28, 28)\n",
      "Mean: 0.02634079\n",
      "Standard deviation: 0.10669048\n",
      "Pickling ../dataset/pickle_data/Eleutherodactylus cochranae.pickle.\n",
      "Full dataset tensor: (200, 28, 28)\n",
      "Mean: 0.044047546\n",
      "Standard deviation: 0.18837175\n",
      "Pickling ../dataset/pickle_data/Eleutherodactylus juanariveroi.pickle.\n",
      "Full dataset tensor: (40, 28, 28)\n",
      "Mean: -0.09829507\n",
      "Standard deviation: 0.08501233\n",
      "Pickling ../dataset/pickle_data/Basileuterus bivittatus.pickle.\n",
      "Full dataset tensor: (120, 28, 28)\n",
      "Mean: -0.02424666\n",
      "Standard deviation: 0.09599042\n",
      "Pickling ../dataset/pickle_data/Chlorothraupis carmioli.pickle.\n",
      "Full dataset tensor: (88, 28, 28)\n",
      "Mean: 0.0028821751\n",
      "Standard deviation: 0.09553957\n",
      "Pickling ../dataset/pickle_data/Hypocnemis subflava.pickle.\n",
      "Full dataset tensor: (192, 28, 28)\n",
      "Mean: 0.0013320959\n",
      "Standard deviation: 0.0984181\n",
      "Pickling ../dataset/pickle_data/Megascops guatemalae.pickle.\n",
      "Full dataset tensor: (48, 28, 28)\n",
      "Mean: 0.08502579\n",
      "Standard deviation: 0.11232977\n",
      "Pickling ../dataset/pickle_data/Eleutherodactylus cooki.pickle.\n",
      "Full dataset tensor: (128, 28, 28)\n",
      "Mean: 0.008656471\n",
      "Standard deviation: 0.11417198\n",
      "Pickling ../dataset/pickle_data/Eleutherodactylus brittoni.pickle.\n",
      "Full dataset tensor: (112, 28, 28)\n",
      "Mean: -0.098023675\n",
      "Standard deviation: 0.12576023\n",
      "Pickling ../dataset/pickle_data/Formicarius analis.pickle.\n",
      "Full dataset tensor: (88, 28, 28)\n",
      "Mean: 0.021810941\n",
      "Standard deviation: 0.11081094\n",
      "Pickling ../dataset/pickle_data/Liosceles thoracicus.pickle.\n",
      "Full dataset tensor: (112, 28, 28)\n",
      "Mean: 0.01671155\n",
      "Standard deviation: 0.11579212\n"
     ]
    }
   ],
   "source": [
    "def maybe_pickle(data_folders, min_num_images_per_class, pickles_path, force=False):\n",
    "    \n",
    "    if not os.path.exists(pickles_path):\n",
    "        os.makedirs(pickles_path)\n",
    "    else:\n",
    "        shutil.rmtree(pickles_path)\n",
    "        os.makedirs(pickles_path)\n",
    "  \n",
    "    dataset_names = []\n",
    "    for folder in data_folders:\n",
    "        class_name = folder.split('/')[-1] # species name\n",
    "        set_filename = pickles_path + '/' + class_name + '.pickle'\n",
    "        dataset_names.append(set_filename)\n",
    "        if os.path.exists(set_filename) and not force:\n",
    "            # You may override by setting force=True.\n",
    "            print('%s already present - Skipping pickling.' % set_filename)\n",
    "        else:\n",
    "            image_files = os.listdir(folder)\n",
    "            count = 0\n",
    "            for image in image_files:\n",
    "                count +=1\n",
    "            if True:#count >= min_num_images_per_class:\n",
    "                print('Pickling %s.' % set_filename)\n",
    "                dataset = load_image(folder, min_num_images_per_class)\n",
    "                try:\n",
    "                    with open(set_filename, 'wb') as f:\n",
    "                        pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "                except Exception as e:\n",
    "                    print('Unable to save data to', set_filename, ':', e)\n",
    "\n",
    "    return dataset_names\n",
    "\n",
    "pickles_path = '../dataset/pickle_data'\n",
    "datasets = maybe_pickle(dataset_folders, min_imgs_per_class, pickles_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 16 classes\n"
     ]
    }
   ],
   "source": [
    "pickles = getDatasetFolders('../dataset/pickle_data')\n",
    "#print(datasets)\n",
    "num_classes = len(pickles)\n",
    "print(f'We have {num_classes} classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to evaluate the number of classes and how are they distributed. Also, observe which species has a higher frequency, etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's see if the dataset is balanced:\n",
      "The total number of images in class Megascops nudipes is: 120\n",
      "The total number of images in class Eleutherodactylus cooki is: 128\n",
      "The total number of images in class Epinephelus guttatus is: 136\n",
      "The total number of images in class Microcerculus marginatus is: 96\n",
      "The total number of images in class Basileuterus chrysogaster is: 40\n",
      "The total number of images in class Myrmeciza hemimelaena is: 352\n",
      "The total number of images in class Megascops guatemalae is: 48\n",
      "The total number of images in class Eleutherodactylus cochranae is: 200\n",
      "The total number of images in class Basileuterus bivittatus is: 120\n",
      "The total number of images in class Eleutherodactylus brittoni is: 112\n",
      "The total number of images in class Formicarius analis is: 88\n",
      "The total number of images in class Eleutherodactylus juanariveroi is: 40\n",
      "The total number of images in class Liosceles thoracicus is: 112\n",
      "The total number of images in class Eleutherodactylus coqui is: 104\n",
      "The total number of images in class Hypocnemis subflava is: 192\n",
      "The total number of images in class Chlorothraupis carmioli is: 88\n",
      "For the dataset to be balanced, each class should have approximately 123 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculates the total of images per class\n",
    "def class_is_balanced(pickles):\n",
    "    total = 0\n",
    "    for pckle in pickles:\n",
    "        if (os.path.isfile(pckle)):\n",
    "            pickle_class = pickle.load(open(pckle, \"rb\"))\n",
    "        else:\n",
    "            print(\"Error reading dataset %s. Exiting.\", pickle_path)\n",
    "            return -1\n",
    "        class_name = pckle.split('/')[-1].split('.')[0]\n",
    "        print(\"The total number of images in class %s is: %d\" % (class_name, len(pickle_class)))\n",
    "        total += len(pickle_class)\n",
    "    print(\"For the dataset to be balanced, each class should have approximately %d images.\\n\" % (total / len(pickles)))\n",
    "    return (total // len(pickles))\n",
    "    \n",
    "print(\"Let's see if the dataset is balanced:\")\n",
    "balance_num = class_is_balanced(pickles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Testing, and Validation Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with every implementation of Supervised Learning, we separate the dataset into three components. The training, the testing, and the validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def das_labeler(pickle_files):\n",
    "    labels = []\n",
    "    images = []\n",
    "    for label, pickle_file in enumerate(pickle_files):\n",
    "        try:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                species_set = pickle.load(f)\n",
    "                for image in species_set:\n",
    "                    labels.append(label)\n",
    "                    images.append(image)\n",
    "        except Exception as e:\n",
    "            print('Unable to process data from', pickle_file, ':', e)\n",
    "            pass\n",
    "    labels = np.asarray(labels)\n",
    "    images = np.asarray(images)\n",
    "    return labels, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, images = das_labeler(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We output the data in a pickle format, to be used next on the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = '../dataset/arbimon_' + str(num_shifts) + '.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': X_train,\n",
    "    'train_labels': y_train,\n",
    "    'test_dataset': X_test,\n",
    "    'test_labels': y_test,\n",
    "    } \n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL) # save all out datasets in one pickle \n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

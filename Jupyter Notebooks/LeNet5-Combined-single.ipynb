{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.layers import flatten\n",
    "from PIL import Image, ImageOps\n",
    "from scipy.ndimage.interpolation import shift \n",
    "from IPython.display import Image as Im \n",
    "from sklearn.utils import shuffle\n",
    "import sklearn\n",
    "import pandas\n",
    "\n",
    "# Our \"library\"\n",
    "from data_augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = '../dataset/arbimon_0.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(aug_shifts, pickle_file):\n",
    "    print(\"=====================\")\n",
    "    print(\"Aug Shifts: \" + str(aug_shifts + 1))\n",
    "    \n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        save = pickle.load(f)\n",
    "        train_dataset = save['train_dataset']\n",
    "        train_labels = save['train_labels']\n",
    "        test_dataset = save['test_dataset']\n",
    "        test_labels = save['test_labels']\n",
    "        del save\n",
    "\n",
    "    print('Original Training Set Shape: ', train_dataset.shape, train_labels.shape)\n",
    "    print('Original Test Set Shape: ', test_dataset.shape, test_labels.shape)\n",
    "    \n",
    "    augmented_train_dataset, augmented_train_labels = combined_augmentation_single(train_dataset, aug_shifts, train_labels)\n",
    "    #augmented_test_dataset, augmented_test_labels = combined_augmentation(test_dataset, aug_shifts, test_labels)    \n",
    "    \n",
    "    print()\n",
    "    print('Augmented Training Set Shape: ', augmented_train_dataset.shape, augmented_train_labels.shape)\n",
    "    #print('Augmented Test Set Shape: ', augmented_test_dataset.shape, augmented_test_labels.shape)\n",
    "    \n",
    "    augmented_train_dataset = reformat(augmented_train_dataset)\n",
    "    #augmented_test_dataset = reformat(augmented_test_dataset)\n",
    "    test_dataset = reformat(test_dataset)\n",
    "    \n",
    "    X_train = np.pad(augmented_train_dataset, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    #X_test = np.pad(augmented_test_dataset, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    test_dataset = np.pad(test_dataset, ((0,0), (2,2), (2,2), (0,0)), 'constant')\n",
    "    \n",
    "    y_train = augmented_train_labels\n",
    "    #y_test = augmented_test_labels\n",
    "    \n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    \n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 5\n",
    "    rate = 0.05\n",
    " \n",
    "    x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "    y = tf.placeholder(tf.int32, (None))\n",
    "    one_hot_y = tf.one_hot(y, 21)\n",
    "    \n",
    "    logits = LeNet(x)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = one_hot_y)\n",
    "    loss_operation = tf.reduce_mean(cross_entropy)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = rate)\n",
    "    training_operation = optimizer.minimize(loss_operation)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "    accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    def evaluate(X_data, y_data):\n",
    "        sess = tf.get_default_session()\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: X_data, y: y_data})\n",
    "        return accuracy\n",
    "    \n",
    "    #augmented_rendimiento = []\n",
    "    #augmented_confusion_matrices = []\n",
    "    \n",
    "    non_augmented_rendimiento = []\n",
    "    non_augmented_confusion_matrices = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        print()\n",
    "        print(\"Sample #\",  str(i+1))\n",
    "        #augmented_prediction_labels = []\n",
    "        non_augmented_prediction_labels = []\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            num_examples = len(X_train)\n",
    "\n",
    "            for i in range(EPOCHS):\n",
    "                X_train, y_train = shuffle(X_train, y_train)\n",
    "                for offset in range(0, num_examples, BATCH_SIZE):\n",
    "                    end = offset + BATCH_SIZE\n",
    "                    batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "                    sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "                train_accuracy = evaluate(X_train, y_train)\n",
    "                if (i%10 == 0):\n",
    "                    print(\"EPOCH {} \".format(i+1))\n",
    "\n",
    "            probs = tf.nn.softmax(logits)\n",
    "            \n",
    "            #augmented_test_accuracy = evaluate(X_test, y_test)\n",
    "            #augmented_predictions = sess.run(probs, feed_dict={x: X_test, y: y_test})\n",
    "            #print(\"Augmented Test Accuracy = {:.3f}\".format(augmented_test_accuracy))\n",
    "            \n",
    "            non_augmented_test_accuracy = evaluate(test_dataset, test_labels)\n",
    "            non_augmented_predictions = sess.run(probs, feed_dict={x: test_dataset, y: test_labels})\n",
    "            print(\"Non-Augmented Test Accuracy = {:.3f}\".format(non_augmented_test_accuracy))\n",
    "\n",
    "        #for prediction in  augmented_predictions:\n",
    "         #   augmented_prediction_labels.append(np.argmax(prediction))\n",
    "            \n",
    "        #with tf.Session() as sess:\n",
    "            #augmented_cm = sklearn.metrics.confusion_matrix(y_test, augmented_prediction_labels)\n",
    "           \n",
    "        \n",
    "        for prediction in  non_augmented_predictions:\n",
    "            non_augmented_prediction_labels.append(np.argmax(prediction))\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            non_augmented_cm = sklearn.metrics.confusion_matrix(test_labels, non_augmented_prediction_labels)\n",
    "            \n",
    "        #augmented_rendimiento.append(augmented_test_accuracy)\n",
    "        #augmented_confusion_matrices.append([augmented_cm])\n",
    "        \n",
    "        non_augmented_rendimiento.append(non_augmented_test_accuracy)\n",
    "        non_augmented_confusion_matrices.append([non_augmented_cm])\n",
    "        \n",
    "    #augmented_confusion_data.loc[len(augmented_confusion_data)] = augmented_confusion_matrices\n",
    "    #augmented_performance.loc[len(augmented_performance)] = augmented_rendimiento\n",
    "    \n",
    "    non_augmented_confusion_data.loc[len(non_augmented_confusion_data)] = non_augmented_confusion_matrices\n",
    "    non_augmented_performance.loc[len(non_augmented_performance)] = non_augmented_rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Aug Shifts: 1\n",
      "Original Training Set Shape:  (165, 28, 28) (165,)\n",
      "Original Test Set Shape:  (82, 28, 28) (82,)\n",
      "\n",
      "Augmented Training Set Shape:  (1320, 28, 28) (1320,)\n",
      "WARNING:tensorflow:From <ipython-input-3-abaede4086c8>:45: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "\n",
      "Sample # 1\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.854\n",
      "\n",
      "Sample # 2\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.793\n",
      "\n",
      "Sample # 3\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.829\n",
      "\n",
      "Sample # 4\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.854\n",
      "\n",
      "Sample # 5\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.817\n",
      "=====================\n",
      "Aug Shifts: 2\n",
      "Original Training Set Shape:  (165, 28, 28) (165,)\n",
      "Original Test Set Shape:  (82, 28, 28) (82,)\n",
      "\n",
      "Augmented Training Set Shape:  (1320, 28, 28) (1320,)\n",
      "\n",
      "Sample # 1\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.915\n",
      "\n",
      "Sample # 2\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.878\n",
      "\n",
      "Sample # 3\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.854\n",
      "\n",
      "Sample # 4\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.805\n",
      "\n",
      "Sample # 5\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.854\n",
      "=====================\n",
      "Aug Shifts: 3\n",
      "Original Training Set Shape:  (165, 28, 28) (165,)\n",
      "Original Test Set Shape:  (82, 28, 28) (82,)\n",
      "\n",
      "Augmented Training Set Shape:  (1320, 28, 28) (1320,)\n",
      "\n",
      "Sample # 1\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.927\n",
      "\n",
      "Sample # 2\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.878\n",
      "\n",
      "Sample # 3\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.854\n",
      "\n",
      "Sample # 4\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.915\n",
      "\n",
      "Sample # 5\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.866\n",
      "=====================\n",
      "Aug Shifts: 4\n",
      "Original Training Set Shape:  (165, 28, 28) (165,)\n",
      "Original Test Set Shape:  (82, 28, 28) (82,)\n",
      "\n",
      "Augmented Training Set Shape:  (1320, 28, 28) (1320,)\n",
      "\n",
      "Sample # 1\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.915\n",
      "\n",
      "Sample # 2\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.939\n",
      "\n",
      "Sample # 3\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.963\n",
      "\n",
      "Sample # 4\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.927\n",
      "\n",
      "Sample # 5\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.915\n",
      "=====================\n",
      "Aug Shifts: 5\n",
      "Original Training Set Shape:  (165, 28, 28) (165,)\n",
      "Original Test Set Shape:  (82, 28, 28) (82,)\n",
      "\n",
      "Augmented Training Set Shape:  (1320, 28, 28) (1320,)\n",
      "\n",
      "Sample # 1\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.878\n",
      "\n",
      "Sample # 2\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.976\n",
      "\n",
      "Sample # 3\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.915\n",
      "\n",
      "Sample # 4\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.927\n",
      "\n",
      "Sample # 5\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.939\n",
      "=====================\n",
      "Aug Shifts: 6\n",
      "Original Training Set Shape:  (165, 28, 28) (165,)\n",
      "Original Test Set Shape:  (82, 28, 28) (82,)\n",
      "\n",
      "Augmented Training Set Shape:  (1320, 28, 28) (1320,)\n",
      "\n",
      "Sample # 1\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.829\n",
      "\n",
      "Sample # 2\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.854\n",
      "\n",
      "Sample # 3\n",
      "EPOCH 1 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.793\n",
      "\n",
      "Sample # 4\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.805\n",
      "\n",
      "Sample # 5\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.878\n",
      "=====================\n",
      "Aug Shifts: 7\n",
      "Original Training Set Shape:  (165, 28, 28) (165,)\n",
      "Original Test Set Shape:  (82, 28, 28) (82,)\n",
      "\n",
      "Augmented Training Set Shape:  (1320, 28, 28) (1320,)\n",
      "\n",
      "Sample # 1\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.768\n",
      "\n",
      "Sample # 2\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.841\n",
      "\n",
      "Sample # 3\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.866\n",
      "\n",
      "Sample # 4\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.854\n",
      "\n",
      "Sample # 5\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.817\n",
      "=====================\n",
      "Aug Shifts: 8\n",
      "Original Training Set Shape:  (165, 28, 28) (165,)\n",
      "Original Test Set Shape:  (82, 28, 28) (82,)\n",
      "\n",
      "Augmented Training Set Shape:  (1320, 28, 28) (1320,)\n",
      "\n",
      "Sample # 1\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.817\n",
      "\n",
      "Sample # 2\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.744\n",
      "\n",
      "Sample # 3\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.732\n",
      "\n",
      "Sample # 4\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.817\n",
      "\n",
      "Sample # 5\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.793\n",
      "=====================\n",
      "Aug Shifts: 9\n",
      "Original Training Set Shape:  (165, 28, 28) (165,)\n",
      "Original Test Set Shape:  (82, 28, 28) (82,)\n",
      "\n",
      "Augmented Training Set Shape:  (1320, 28, 28) (1320,)\n",
      "\n",
      "Sample # 1\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.720\n",
      "\n",
      "Sample # 2\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.671\n",
      "\n",
      "Sample # 3\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n",
      "EPOCH 41 \n",
      "Non-Augmented Test Accuracy = 0.732\n",
      "\n",
      "Sample # 4\n",
      "EPOCH 1 \n",
      "EPOCH 11 \n",
      "EPOCH 21 \n",
      "EPOCH 31 \n"
     ]
    }
   ],
   "source": [
    "#augmented_confusion_data = pandas.DataFrame(columns = list('12345'))\n",
    "#augmented_performance = pandas.DataFrame(columns = list('12345'))\n",
    "\n",
    "non_augmented_confusion_data = pandas.DataFrame(columns = list('12345'))\n",
    "non_augmented_performance = pandas.DataFrame(columns = list('12345'))\n",
    "\n",
    "\n",
    "for i in range(22):\n",
    "    execute(aug_shifts = i, pickle_file = pickle_file)\n",
    "    \n",
    "#augmented_performance.to_pickle('results/combined_augmented_test/performance_combined_augmented_test.pkl')\n",
    "#augmented_confusion_data.to_pickle('results/combined_augmented_test/confusion_matrices_combined_augmented_test.pkl')\n",
    "\n",
    "non_augmented_confusion_data.to_pickle('results_single/combined_non_augmented_test/confusion_matrices_combined_non_augmented_test.pkl')\n",
    "non_augmented_performance.to_pickle('results_single/combined_non_augmented_test/performance_combined_non_augmented_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
